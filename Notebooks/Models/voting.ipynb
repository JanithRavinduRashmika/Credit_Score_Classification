{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../Data/cleanedNotRecoded.csv\")\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "df = df.drop([\"ID\", \"Customer_ID\", \"Name\", \"SSN\", \"Occupation\"], axis=1)\n",
    "\n",
    "df[\"Credit_Score\"] = df[\"Credit_Score\"].map({\"Good\":2, \"Standard\":1, \"Poor\":0})\n",
    "df[\"Credit_Mix\"] = df[\"Credit_Mix\"].map({\"Good\":2, \"Standard\":1, \"Bad\":0})\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Payment_of_Min_Amount', 'Payment_Behaviour'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iforestModel = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n",
    "\n",
    "iforestModel.fit(df)\n",
    "\n",
    "# Predict anomalies (-1 for outliers, 1 for inliers)\n",
    "df['anomaly'] = iforestModel.predict(df)\n",
    "\n",
    "df = df[df['anomaly'] == 1].drop(columns=['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Credit_Score\"], axis=1)\n",
    "y = df[\"Credit_Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X, y = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Train======\n",
      "Accuracy: 0.7253334612801074\n",
      "f1_score: 0.7217456983004743\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74     34649\n",
      "           1       0.71      0.59      0.65     34754\n",
      "           2       0.72      0.84      0.78     34807\n",
      "\n",
      "    accuracy                           0.73    104210\n",
      "   macro avg       0.72      0.73      0.72    104210\n",
      "weighted avg       0.72      0.73      0.72    104210\n",
      "\n",
      "Cross-validation accuracy scores: [0.73006429 0.72488245 0.72238749 0.72401881 0.72632185 0.73121581\n",
      " 0.72641781 0.72430669 0.72066021 0.72075617]\n",
      "Mean accuracy: 0.7251031570866521\n",
      "=====Test======\n",
      "Accuracy: 0.7230261390242966\n",
      "f1_score: 0.7198055956994289\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      8772\n",
      "           1       0.70      0.60      0.65      8667\n",
      "           2       0.72      0.84      0.78      8614\n",
      "\n",
      "    accuracy                           0.72     26053\n",
      "   macro avg       0.72      0.72      0.72     26053\n",
      "weighted avg       0.72      0.72      0.72     26053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "\n",
    "nbModel = GaussianNB()\n",
    "svmLModel = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "RgModel = RidgeClassifier()\n",
    "\n",
    "votingclf1 = VotingClassifier(\n",
    "                estimators=[('nb', nbModel), ('svm', svmLModel), ('rg', RgModel)],\n",
    "                voting='hard')\n",
    "votingclf1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = votingclf1.predict(X_train)\n",
    "\n",
    "print(\"=====Train======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_train, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred))\n",
    "\n",
    "scores = cross_val_score(votingclf1, X_train, y_train, cv=stratified_kfold, scoring='accuracy') \n",
    "\n",
    "print(f\"Cross-validation accuracy scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean()}\")\n",
    "\n",
    "y_pred = votingclf1.predict(X_test)\n",
    "\n",
    "print(\"=====Test======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Train======\n",
      "Accuracy: 0.7241051722483447\n",
      "f1_score: 0.7212711002965854\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73     34649\n",
      "           1       0.69      0.61      0.65     34754\n",
      "           2       0.73      0.84      0.78     34807\n",
      "\n",
      "    accuracy                           0.72    104210\n",
      "   macro avg       0.72      0.72      0.72    104210\n",
      "weighted avg       0.72      0.72      0.72    104210\n",
      "\n",
      "Cross-validation accuracy scores: [0.73188753 0.72545821 0.72737741 0.71662988 0.72507437 0.72756933\n",
      " 0.72814509 0.72238749 0.71643796 0.716342  ]\n",
      "Mean accuracy: 0.7237309279339794\n",
      "=====Test======\n",
      "Accuracy: 0.7200322419682954\n",
      "f1_score: 0.7174965231022974\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73      8772\n",
      "           1       0.68      0.62      0.65      8667\n",
      "           2       0.73      0.84      0.78      8614\n",
      "\n",
      "    accuracy                           0.72     26053\n",
      "   macro avg       0.72      0.72      0.72     26053\n",
      "weighted avg       0.72      0.72      0.72     26053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "svmLModel = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "RgModel = RidgeClassifier()\n",
    "logModel = LogisticRegression(multi_class='ovr')\n",
    "\n",
    "votingclf2 = VotingClassifier(\n",
    "                estimators=[('svm', svmLModel), ('rg', RgModel), ('lr', logModel)],\n",
    "                voting='hard')\n",
    "votingclf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = votingclf2.predict(X_train)\n",
    "\n",
    "print(\"=====Train======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_train, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred))\n",
    "\n",
    "scores = cross_val_score(votingclf2, X_train, y_train, cv=stratified_kfold, scoring='accuracy') \n",
    "\n",
    "print(f\"Cross-validation accuracy scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean()}\")\n",
    "\n",
    "y_pred = votingclf2.predict(X_test)\n",
    "\n",
    "print(\"=====Test======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Train======\n",
      "Accuracy: 0.7229056712407639\n",
      "f1_score: 0.719926277992461\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74     34649\n",
      "           1       0.69      0.60      0.64     34754\n",
      "           2       0.73      0.84      0.78     34807\n",
      "\n",
      "    accuracy                           0.72    104210\n",
      "   macro avg       0.72      0.72      0.72    104210\n",
      "weighted avg       0.72      0.72      0.72    104210\n",
      "\n",
      "Cross-validation accuracy scores: [0.71384704 0.72181173 0.72958449 0.72152385 0.7197006  0.72171577\n",
      " 0.72641781 0.72209961 0.72795317 0.72209961]\n",
      "Mean accuracy: 0.7226753670473083\n",
      "=====Test======\n",
      "Accuracy: 0.7187655932138334\n",
      "f1_score: 0.716111074866372\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73      8772\n",
      "           1       0.68      0.61      0.64      8667\n",
      "           2       0.73      0.84      0.78      8614\n",
      "\n",
      "    accuracy                           0.72     26053\n",
      "   macro avg       0.72      0.72      0.72     26053\n",
      "weighted avg       0.72      0.72      0.72     26053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "RgModel = RidgeClassifier()\n",
    "logModel = LogisticRegression(multi_class='ovr')\n",
    "LDAModel = LinearDiscriminantAnalysis()\n",
    "\n",
    "votingclf3 = VotingClassifier(\n",
    "                estimators=[('rg', RgModel), ('lr', logModel), ('lda', LDAModel)],\n",
    "                voting='hard')\n",
    "votingclf3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = votingclf3.predict(X_train)\n",
    "\n",
    "print(\"=====Train======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_train, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred))\n",
    "\n",
    "scores = cross_val_score(votingclf3, X_train, y_train, cv=stratified_kfold, scoring='accuracy') \n",
    "\n",
    "print(f\"Cross-validation accuracy scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean()}\")\n",
    "\n",
    "y_pred = votingclf3.predict(X_test)\n",
    "\n",
    "print(\"=====Test======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Train======\n",
      "Accuracy: 0.729450148738125\n",
      "f1_score: 0.7270954064536475\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74     34649\n",
      "           1       0.69      0.62      0.66     34754\n",
      "           2       0.74      0.84      0.78     34807\n",
      "\n",
      "    accuracy                           0.73    104210\n",
      "   macro avg       0.73      0.73      0.73    104210\n",
      "weighted avg       0.73      0.73      0.73    104210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.73217542 0.72584205 0.72814509 0.72401881 0.73793302 0.72977641\n",
      " 0.7348623  0.72641781 0.73179157 0.72593801]\n",
      "Mean accuracy: 0.7296900489396412\n",
      "=====Test======\n",
      "Accuracy: 0.726480635627375\n",
      "f1_score: 0.7244040042416015\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73      8772\n",
      "           1       0.69      0.63      0.66      8667\n",
      "           2       0.73      0.84      0.78      8614\n",
      "\n",
      "    accuracy                           0.73     26053\n",
      "   macro avg       0.73      0.73      0.72     26053\n",
      "weighted avg       0.73      0.73      0.72     26053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "logModel = LogisticRegression(multi_class='ovr')\n",
    "LDAModel = LinearDiscriminantAnalysis()\n",
    "adaModel = AdaBoostClassifier()\n",
    "\n",
    "votingclf4 = VotingClassifier(\n",
    "                estimators=[('lr', logModel), ('lda', LDAModel), ('ada', adaModel)],\n",
    "                voting='hard')\n",
    "votingclf4.fit(X_train, y_train)\n",
    "\n",
    "y_pred = votingclf4.predict(X_train)\n",
    "\n",
    "print(\"=====Train======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_train, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred))\n",
    "\n",
    "scores = cross_val_score(votingclf4, X_train, y_train, cv=stratified_kfold, scoring='accuracy') \n",
    "\n",
    "print(f\"Cross-validation accuracy scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean()}\")\n",
    "\n",
    "y_pred = votingclf4.predict(X_test)\n",
    "\n",
    "print(\"=====Test======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Train======\n",
      "Accuracy: 0.7425870837731504\n",
      "f1_score: 0.7396118332378583\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76     34649\n",
      "           1       0.73      0.62      0.67     34754\n",
      "           2       0.74      0.85      0.79     34807\n",
      "\n",
      "    accuracy                           0.74    104210\n",
      "   macro avg       0.74      0.74      0.74    104210\n",
      "weighted avg       0.74      0.74      0.74    104210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.73783706 0.7434987  0.74868055 0.74100374 0.74042798 0.74042798\n",
      " 0.7363017  0.7430189  0.74829671 0.74292294]\n",
      "Mean accuracy: 0.7422416274829671\n",
      "=====Test======\n",
      "Accuracy: 0.7372663416880973\n",
      "f1_score: 0.7345866877092023\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      8772\n",
      "           1       0.71      0.63      0.67      8667\n",
      "           2       0.74      0.85      0.79      8614\n",
      "\n",
      "    accuracy                           0.74     26053\n",
      "   macro avg       0.74      0.74      0.73     26053\n",
      "weighted avg       0.74      0.74      0.73     26053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LDAModel = LinearDiscriminantAnalysis()\n",
    "adaModel = AdaBoostClassifier()\n",
    "QDAModel = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "votingclf5 = VotingClassifier(\n",
    "                estimators=[('lda', LDAModel), ('ada', adaModel), ('qda', QDAModel )],\n",
    "                voting='hard')\n",
    "votingclf5.fit(X_train, y_train)\n",
    "\n",
    "y_pred = votingclf5.predict(X_train)\n",
    "\n",
    "print(\"=====Train======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_train, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred))\n",
    "\n",
    "scores = cross_val_score(votingclf5, X_train, y_train, cv=stratified_kfold, scoring='accuracy') \n",
    "\n",
    "print(f\"Cross-validation accuracy scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean()}\")\n",
    "\n",
    "y_pred = votingclf5.predict(X_test)\n",
    "\n",
    "print(\"=====Test======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Train======\n",
      "Accuracy: 0.7578639286057001\n",
      "f1_score: 0.7545859896141368\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78     34649\n",
      "           1       0.76      0.63      0.69     34754\n",
      "           2       0.74      0.87      0.80     34807\n",
      "\n",
      "    accuracy                           0.76    104210\n",
      "   macro avg       0.76      0.76      0.75    104210\n",
      "weighted avg       0.76      0.76      0.75    104210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.75415027 0.75568563 0.75885232 0.76182708 0.75606948 0.74551387\n",
      " 0.75040783 0.76413012 0.75021591 0.7562614 ]\n",
      "Mean accuracy: 0.755311390461568\n",
      "=====Test======\n",
      "Accuracy: 0.7516216942386673\n",
      "f1_score: 0.7486530191477928\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      8772\n",
      "           1       0.74      0.63      0.68      8667\n",
      "           2       0.74      0.87      0.80      8614\n",
      "\n",
      "    accuracy                           0.75     26053\n",
      "   macro avg       0.75      0.75      0.75     26053\n",
      "weighted avg       0.75      0.75      0.75     26053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "adaModel = AdaBoostClassifier()\n",
    "QDAModel = QuadraticDiscriminantAnalysis()\n",
    "svmRBFModel = SVC(kernel='rbf', decision_function_shape='ovr')\n",
    "\n",
    "votingclf6 = VotingClassifier(\n",
    "                estimators=[('ada', adaModel), ('qda', QDAModel ), ('svc', svmRBFModel)],\n",
    "                voting='hard')\n",
    "votingclf6.fit(X_train, y_train)\n",
    "\n",
    "y_pred = votingclf6.predict(X_train)\n",
    "\n",
    "print(\"=====Train======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_train, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred))\n",
    "\n",
    "scores = cross_val_score(votingclf6, X_train, y_train, cv=stratified_kfold, scoring='accuracy') \n",
    "\n",
    "print(f\"Cross-validation accuracy scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean()}\")\n",
    "\n",
    "y_pred = votingclf6.predict(X_test)\n",
    "\n",
    "print(\"=====Test======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Train======\n",
      "Accuracy: 0.7663563957393724\n",
      "f1_score: 0.7636581506484836\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78     34649\n",
      "           1       0.76      0.65      0.70     34754\n",
      "           2       0.75      0.88      0.81     34807\n",
      "\n",
      "    accuracy                           0.77    104210\n",
      "   macro avg       0.77      0.77      0.76    104210\n",
      "weighted avg       0.77      0.77      0.76    104210\n",
      "\n",
      "Cross-validation accuracy scores: [0.757221   0.7600998  0.76422608 0.76000384 0.77430189 0.76029172\n",
      " 0.76739276 0.75962    0.7677766  0.75856444]\n",
      "Mean accuracy: 0.7629498128778428\n",
      "=====Test======\n",
      "Accuracy: 0.7589145204007216\n",
      "f1_score: 0.7563729827588032\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77      8772\n",
      "           1       0.75      0.65      0.69      8667\n",
      "           2       0.75      0.87      0.80      8614\n",
      "\n",
      "    accuracy                           0.76     26053\n",
      "   macro avg       0.76      0.76      0.76     26053\n",
      "weighted avg       0.76      0.76      0.76     26053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "QDAModel = QuadraticDiscriminantAnalysis()\n",
    "svmRBFModel = SVC(kernel='rbf', decision_function_shape='ovr')\n",
    "gbModel = GradientBoostingClassifier()\n",
    "\n",
    "votingclf7 = VotingClassifier(\n",
    "                estimators=[('qda', QDAModel ), ('svc', svmRBFModel), ('gb', gbModel )],\n",
    "                voting='hard')\n",
    "votingclf7.fit(X_train, y_train)\n",
    "\n",
    "y_pred = votingclf7.predict(X_train)\n",
    "\n",
    "print(\"=====Train======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_train, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred))\n",
    "\n",
    "scores = cross_val_score(votingclf7, X_train, y_train, cv=stratified_kfold, scoring='accuracy') \n",
    "\n",
    "print(f\"Cross-validation accuracy scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean()}\")\n",
    "\n",
    "y_pred = votingclf7.predict(X_test)\n",
    "\n",
    "print(\"=====Test======\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
